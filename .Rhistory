plot(trainErr2,main="Training error depending on sigma (second sample")
plot(trainErr1,main="Training error depending on sigma (first sample")
lines(trainErr2,main="Training error depending on sigma (second sample")
lines(trainErr1,main="Training error depending on sigma (first sample")
lines(trainErr2,main="Training error depending on sigma (second sample")
plot(trainErr1,main="Training error depending on sigma (first sample")
lines(trainErr1)
lines(trainErr2,main="Training error depending on sigma (second sample")
plot(trainErr1,main="Training error depending on sigma",col="red",type="S")
?plot
plot(trainErr1,main="Training error depending on sigma",col="red",type="l")
lines(trainErr2,col="blue")
legend(1, 95, legend=c("Sample 1", "Sample 2"), col=c("red", "blue"), lty=1:2, cex=0.8)
plot(trainErr1,main="Training error depending on sigma",col="red",type="l")
lines(trainErr2,col="blue")
legend(0.002, 0.006, legend=c("Sample 1", "Sample 2"), col=c("red", "blue"), lty=1:2, cex=0.8)
legend("right",0.002, 0.006, legend=c("Sample 1", "Sample 2"), col=c("red", "blue"), lty=1:2, cex=0.8)
plot(trainErr1,main="Training error depending on sigma",col="red",type="l")
lines(trainErr2,col="blue")
legend("right",0.002, 0.006, legend=c("Sample 1", "Sample 2"), col=c("red", "blue"), lty=1, cex=0.8)
plot(trainErr1,main="Training error depending on sigma",col="red",type="l")
lines(trainErr2,col="blue")
legend("right",0.002, 0.006, legend=c("Sample 1", "Sample 2"), col=c("red", "blue"), lty=1)
plot(trainErr1,main="Training error depending on sigma",col="red",type="l",
xlab="Sigma",ylab="Training error")
lines(trainErr2,col="blue")
legend("right",0.002, 0.006, legend=c("Sample 1", "Sample 2"), col=c("red", "blue"), lty=1)
REZsvm
?ksvm
REZsvm$alpha
REZsvm["alpha"]
REZsvm$coef
REZsvm["coef"]
REZsvm(nSV)
REZsvm[nSV]
REZsvm["nSV"]
REZsvm$nSV
##########################################################
# The package "kernlab"
##########################################################
##########################################################
# To install the package "kernlab" execute:
# En R cliquer: "Packages" ->  Installer le(s) package(s) -> [...France (Lyon2)...] -> kernlab
library("kernlab")  # connect library
#################################################################################################################################
#################################################################################################################################
#################################################################################################################################
set.seed(123)
# Generate two dimensional data
nn=500
mu1=c(0,0)
X = mu1 + cbind(rnorm(nn),rnorm(nn))
d = apply(X^2,MARGIN=1,sum)
Y = ifelse(d<1,1,2)
# visualise
plot(X,col=c("red","yellow","blue")[Y])
#En utilisant ksvm with kernel = "vanilladot", on obtient
?ksvm
REZsvm = ksvm(X,Y,kernel="vanilladot",type="C-svc",cross=0,C=100/nn)
plot(REZsvm,data=X)
REZsvm
#vanilladot indique qu'il n'y a pas de noyau, ou plutôt le noyau trivial
#avec "rbfdot"
REZsvm = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=2),type="C-svc",cross=0,C=50)
plot(REZsvm,data=X) #ne marche qu'en bidimensionnel
REZsvm
Ypred=predict(REZsvm)
sum(Ypred==Y)/length(Y)
1-sum(Ypred==Y)/length(Y) #correspond à la training error de REZsvm
REZsvm
#Test avec d'autres valeurs
m=1230
mu2=c(0,0)
X2 = mu2 + cbind(rnorm(m),rnorm(m))
d2 = apply(X2^2,MARGIN=1,sum)
Y2 = ifelse(d2<1,1,2)
plot(X2,col=c("red","blue")[Y2])
predict(REZsvm,Y2)
predict(REZsvm,Y2[1:nn])
fitted(REZsvm)
data("iris")
names(iris)
###########
A=0.01
B=100
M=20
exp(seq(log(A),log(B),length=M))
############################################################################
#Test en variant sigma
trainErr1=c()
trainErr2=c()
A=0.01
B=100
M=20
sigmaValues=exp(seq(log(A),log(B),length=M))
for (i in sigmaValues){
REZsvmi = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=i),type="C-svc",cross=0,C=50)
Ypredi=predict(REZsvmi)
trainErr1[i]=1-sum(Ypredi==Y)/length(Y)
REZsvmi2 = ksvm(X2,Y2,kernel="rbfdot", kpar=list(sigma=i),type="C-svc",cross=0,C=50)
Ypredi2=predict(REZsvmi2)
trainErr2[i]=1-sum(Ypredi2==Y2)/length(Y2)
}
plot(sigmaValues,trainErr1,main="Training error depending on sigma",col="red",type="l",
xlab="Sigma",ylab="Training error")
############################################################################
#Test en variant sigma
trainErr1=c()
trainErr2=c()
A=0.01
B=100
M=20
sigmaValues=exp(seq(log(A),log(B),length=M))
for (i in 1:length(sigmaValues)){
REZsvmi = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=sigmaValues[i]),type="C-svc",cross=0,C=50)
Ypredi=predict(REZsvmi)
trainErr1[i]=1-sum(Ypredi==Y)/length(Y)
REZsvmi2 = ksvm(X2,Y2,kernel="rbfdot", kpar=list(sigma=sigmaValues[i]),type="C-svc",cross=0,C=50)
Ypredi2=predict(REZsvmi2)
trainErr2[i]=1-sum(Ypredi2==Y2)/length(Y2)
}
plot(sigmaValues,trainErr1,main="Training error depending on sigma",col="red",type="l",
xlab="Sigma",ylab="Training error")
lines(trainErr2,col="blue")
plot(sigmaValues,trainErr1,main="Training error depending on sigma",col="red",type="l",
xlab="Sigma",ylab="Training error")
lines(sigmaValues,trainErr2,col="blue")
legend("right",0.002, 0.006, legend=c("Sample 1", "Sample 2"),
col=c("red", "blue"), lty=1)
sigmaValues
A=0.01
B=100
M=20
sigmaValues=exp(seq(log(A),log(B),length=M))
for (i in 2:length(sigmaValues)){
REZsvmi = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=sigmaValues[i]),type="C-svc",cross=0,C=50)
Ypredi=predict(REZsvmi)
trainErr1[i]=1-sum(Ypredi==Y)/length(Y)
REZsvmi2 = ksvm(X2,Y2,kernel="rbfdot", kpar=list(sigma=sigmaValues[i]),type="C-svc",cross=0,C=50)
Ypredi2=predict(REZsvmi2)
trainErr2[i]=1-sum(Ypredi2==Y2)/length(Y2)
}
plot(sigmaValues,trainErr1,main="Training error depending on sigma",col="red",type="l",
xlab="Sigma",ylab="Training error")
lines(sigmaValues,trainErr2,col="blue")
############################################################################
#Test en variant sigma
trainErr1=c()
trainErr2=c()
A=0.01
B=100
M=20
sigmaValues=exp(seq(log(A),log(B),length=M))
for (i in 1:length(sigmaValues)){
REZsvmi = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=sigmaValues[i]),type="C-svc",cross=0,C=50)
Ypredi=predict(REZsvmi)
trainErr1[i]=1-sum(Ypredi==Y)/length(Y)
REZsvmi2 = ksvm(X2,Y2,kernel="rbfdot", kpar=list(sigma=sigmaValues[i]),type="C-svc",cross=0,C=50)
Ypredi2=predict(REZsvmi2)
trainErr2[i]=1-sum(Ypredi2==Y2)/length(Y2)
}
plot(sigmaValues,trainErr1,main="Training error depending on sigma",col="red",type="l",
xlab="Sigma",ylab="Training error")
lines(sigmaValues,trainErr2,col="blue")
legend("right",0.002, 0.006, legend=c("Sample 1", "Sample 2"),
col=c("red", "blue"), lty=1)
##########################################################
# The package "kernlab"
##########################################################
##########################################################
# To install the package "kernlab" execute:
# En R cliquer: "Packages" ->  Installer le(s) package(s) -> [...France (Lyon2)...] -> kernlab
library("kernlab")  # connect library
#################################################################################################################################
#################################################################################################################################
#################################################################################################################################
set.seed(123)
# Generate two dimensional data
nn=500
mu1=c(0,0)
X = mu1 + cbind(rnorm(nn),rnorm(nn))
d = apply(X^2,MARGIN=1,sum)
Y = ifelse(d<1,1,2)
# visualise
plot(X,col=c("red","yellow","blue")[Y])
#En utilisant ksvm with kernel = "vanilladot", on obtient
?ksvm
REZsvm = ksvm(X,Y,kernel="vanilladot",type="C-svc",cross=0,C=100/nn)
plot(REZsvm,data=X)
REZsvm
#vanilladot indique qu'il n'y a pas de noyau, ou plutôt le noyau trivial
#avec "rbfdot"
REZsvm = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=2),type="C-svc",cross=0,C=50)
plot(REZsvm,data=X) #ne marche qu'en bidimensionnel
REZsvm
Ypred=predict(REZsvm)
sum(Ypred==Y)/length(Y)
1-sum(Ypred==Y)/length(Y) #correspond à la training error de REZsvm
REZsvm
#############################################################################
#Test avec d'autres valeurs
m=1230
mu2=c(0,0)
X2 = mu2 + cbind(rnorm(m),rnorm(m))
d2 = apply(X2^2,MARGIN=1,sum)
Y2 = ifelse(d2<1,1,2)
plot(X2,col=c("red","blue")[Y2])
predict(REZsvm,newdata=Y2)
predict(REZsvm,newdata=X2)
newPred=predict(REZsvm,newdata=X2)
newPred=predict(REZsvm,newdata=X2)
sum(newPred==Y2)/length(Y2)
1-sum(newPred==Y2)/length(Y2)
REZsvm2 = ksvm(X2,Y2,kernel="rbfdot", kpar=list(sigma=2),type="C-svc",cross=0,C=50)
plot(REZsvm2,data=X2)
Ypred2=predict(REZsvm2)
sum(Ypred==Y2)/length(Y2)
sum(Ypred2==Y2)/length(Y2)
1-sum(Ypred2==Y2)/length(Y2)
REZsvm2
?ksvm
###########
#Cross validation
cross(REZsvm)
REZcross = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=2),type="C-svc",cross=0,C=50)
cross(REZcross)
REZcross = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=2),type="C-svc",cross=5,C=50)
cross(REZcross)
REZcross = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=2),type="C-svc",cross=4,C=50)
cross(REZcross)
REZcross = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=2),type="C-svc",cross=6,C=50)
cross(REZcross)
REZcross = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=2),type="C-svc",cross=7,C=50)
cross(REZcross)
REZcross = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=2),type="C-svc",cross=8,C=50)
cross(REZcross)
REZcross = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=2),type="C-svc",cross=3,C=50)
cross(REZcross)
REZcross = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=2),type="C-svc",cross=2,C=50)
cross(REZcross)
REZcross = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=2),type="C-svc",cross=1,C=50)
cross(REZcross)
REZcross = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=2),type="C-svc",cross=10,C=50)
cross(REZcross)
REZcross = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=2),type="C-svc",cross=8,C=50)
cross(REZcross)
REZcross = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=2),type="C-svc",cross=9,C=50)
cross(REZcross)
set.seed(123)
REZcross = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=2),type="C-svc",cross=8,C=50)
cross(REZcross)
REZcross = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=2),type="C-svc",cross=7,C=50)
cross(REZcross)
REZcross = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=2),type="C-svc",cross=9,C=50)
cross(REZcross)
REZcross = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=2),type="C-svc",cross=10,C=50)
cross(REZcross)
REZcross = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=2),type="C-svc",cross=5,C=50)
cross(REZcross)
REZcross = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=2),type="C-svc",cross=4,C=50)
cross(REZcross)
REZcross = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=2),type="C-svc",cross=3,C=50)
cross(REZcross)
REZcross = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=2),type="C-svc",cross=12,C=50)
cross(REZcross)
set.seed(123)
# Generate two dimensional data
nn=500
mu1=c(0,0)
X = mu1 + cbind(rnorm(nn),rnorm(nn))
d = apply(X^2,MARGIN=1,sum)
Y = ifelse(d<1,1,2)
plot(X,col=c("red","yellow","blue")[Y])
#En utilisant ksvm with kernel = "vanilladot", on obtient
?ksvm
REZsvm = ksvm(X,Y,kernel="vanilladot",type="C-svc",cross=0,C=100/nn)
plot(REZsvm,data=X)
REZsvm
#vanilladot indique qu'il n'y a pas de noyau, ou plutôt le noyau trivial
#avec "rbfdot"
REZsvm = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=2),type="C-svc",cross=0,C=50)
plot(REZsvm,data=X) #ne marche qu'en bidimensionnel
REZsvm
Ypred=predict(REZsvm)
sum(Ypred==Y)/length(Y)
1-sum(Ypred==Y)/length(Y) #correspond à la training error de REZsvm
REZsvm
#############################################################################
#Test avec d'autres valeurs
m=1230
mu2=c(0,0)
X2 = mu2 + cbind(rnorm(m),rnorm(m))
d2 = apply(X2^2,MARGIN=1,sum)
Y2 = ifelse(d2<1,1,2)
plot(X2,col=c("red","blue")[Y2])
newPred=predict(REZsvm,newdata=X2)
sum(newPred==Y2)/length(Y2)
1-sum(newPred==Y2)/length(Y2)
REZsvm2 = ksvm(X2,Y2,kernel="rbfdot", kpar=list(sigma=2),type="C-svc",cross=0,C=50)
plot(REZsvm2,data=X2)
Ypred2=predict(REZsvm2)
sum(Ypred2==Y2)/length(Y2)
1-sum(Ypred2==Y2)/length(Y2)
REZsvm2
############################################################################
#Test en variant sigma
trainErr1=c()
trainErr2=c()
A=0.01
B=100
M=20
sigmaValues=exp(seq(log(A),log(B),length=M))
for (i in 1:length(sigmaValues)){
REZsvmi = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=sigmaValues[i]),type="C-svc",cross=0,C=50)
Ypredi=predict(REZsvmi)
trainErr1[i]=1-sum(Ypredi==Y)/length(Y)
REZsvmi2 = ksvm(X2,Y2,kernel="rbfdot", kpar=list(sigma=sigmaValues[i]),type="C-svc",cross=0,C=50)
Ypredi2=predict(REZsvmi2)
trainErr2[i]=1-sum(Ypredi2==Y2)/length(Y2)
}
plot(sigmaValues,trainErr1,main="Training error depending on sigma",col="red",type="l",
xlab="Sigma",ylab="Training error")
lines(sigmaValues,trainErr2,col="blue")
legend("right",0.002, 0.006, legend=c("Sample 1", "Sample 2"),
col=c("red", "blue"), lty=1)
for (i in 1:30){
REZsvmi = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=sigmaValues[i]),type="C-svc",cross=0,C=50)
Ypredi=predict(REZsvmi)
trainErr1[i]=1-sum(Ypredi==Y)/length(Y)
REZsvmi2 = ksvm(X2,Y2,kernel="rbfdot", kpar=list(sigma=sigmaValues[i]),type="C-svc",cross=0,C=50)
Ypredi2=predict(REZsvmi2)
trainErr2[i]=1-sum(Ypredi2==Y2)/length(Y2)
}
plot(sigmaValues,trainErr1,main="Training error depending on sigma",col="red",type="l",
xlab="Sigma",ylab="Training error")
lines(sigmaValues,trainErr2,col="blue")
sigmaValues
plot(sigmaValues,trainErr1,main="Training error depending on sigma",col="red",type="l",
xlab="Sigma",ylab="Training error")
lines(sigmaValues,trainErr2,col="blue")
legend("right",0.002, 0.006, legend=c("Sample 1", "Sample 2"),
col=c("red", "blue"), lty=1)
for (i in 1:30){
REZsvmi = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=i),type="C-svc",cross=0,C=50)
Ypredi=predict(REZsvmi)
trainErr1[i]=1-sum(Ypredi==Y)/length(Y)
REZsvmi2 = ksvm(X2,Y2,kernel="rbfdot", kpar=list(sigma=i),type="C-svc",cross=0,C=50)
Ypredi2=predict(REZsvmi2)
trainErr2[i]=1-sum(Ypredi2==Y2)/length(Y2)
}
plot(sigmaValues,trainErr1,main="Training error depending on sigma",col="red",type="l",
xlab="Sigma",ylab="Training error")
lines(sigmaValues,trainErr2,col="blue")
legend("right",0.002, 0.006, legend=c("Sample 1", "Sample 2"),
col=c("red", "blue"), lty=1)
############################################################################
#Test en variant sigma
trainErr1=c()
trainErr2=c()
############################################################################
#Test en variant sigma
trainErr1=c()
trainErr2=c()
A=0.01
B=100
M=20
sigmaValues=exp(seq(log(A),log(B),length=M))
for (i in 1:length(sigmaValues)){
REZsvmi = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=sigmaValues[i]),type="C-svc",cross=0,C=50)
Ypredi=predict(REZsvmi)
trainErr1[i]=1-sum(Ypredi==Y)/length(Y)
newPred=predict(REZsvm,newdata=X2)
sum(newPred==Y2)/length(Y2)
trainErr2[i]1-sum(newPred==Y2)/length(Y2)
}
############################################################################
#Test en variant sigma
trainErr1=c()
trainErr2=c()
A=0.01
B=100
M=20
sigmaValues=exp(seq(log(A),log(B),length=M))
for (i in 1:length(sigmaValues)){
REZsvmi = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=sigmaValues[i]),type="C-svc",cross=0,C=50)
Ypredi=predict(REZsvmi)
trainErr1[i]=1-sum(Ypredi==Y)/length(Y)
newPred=predict(REZsvm,newdata=X2)
trainErr2[i]=1-sum(newPred==Y2)/length(Y2)
}
plot(sigmaValues,trainErr1,main="Training error depending on sigma",col="red",type="l",
xlab="Sigma",ylab="Training error")
lines(sigmaValues,trainErr2,col="blue")
legend("right",0.002, 0.006, legend=c("Sample 1", "Sample 2"),
col=c("red", "blue"), lty=1)
trainErr1=c()
trainErr2=c()
A=0.01
B=100
M=20
sigmaValues=exp(seq(log(A),log(B),length=M))
for (i in 1:length(sigmaValues)){
REZsvmi = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=sigmaValues[i]),type="C-svc",cross=0,C=50)
Ypredi=predict(REZsvmi)
trainErr1[i]=1-sum(Ypredi==Y)/length(Y)
newPredi=predict(REZsvmi,newdata=X2)
trainErr2[i]=1-sum(newPredi==Y2)/length(Y2)
}
plot(sigmaValues,trainErr1,main="Training error depending on sigma",col="red",type="l",
xlab="Sigma",ylab="Training error")
lines(sigmaValues,trainErr2,col="blue")
legend("right",0.002, 0.006, legend=c("Sample 1", "Sample 2"),
col=c("red", "blue"), lty=1)
plot(log(sigmaValues),trainErr1,main="Training error depending on sigma",col="red",type="l",
xlab="Log Sigma",ylab="Error")
lines(log(sigmaValues),trainErr2,col="blue")
legend("right",0.002, 0.006, legend=c("Training error", "Verificatione error"),
col=c("red", "blue"), lty=1)
plot(log(sigmaValues),trainErr1,main="Training error depending on sigma",col="red",type="l",
xlab="Log Sigma",ylab="Error")
lines(log(sigmaValues),trainErr2,col="blue")
legend("right",0.002, 0.006, legend=c("Training error", "Verification error"),
col=c("red", "blue"), lty=1)
#Test en variant sigma
trainErr=c()
verifError=c()
A=0.01
B=100
M=20
sigmaValues=exp(seq(log(A),log(B),length=M))
for (i in 1:length(sigmaValues)){
REZsvmi = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=sigmaValues[i]),type="C-svc",cross=0,C=50)
Ypredi=predict(REZsvmi)
trainErr[i]=1-sum(Ypredi==Y)/length(Y)
newPredi=predict(REZsvmi,newdata=X2)
verifError[i]=1-sum(newPredi==Y2)/length(Y2)
}
plot(log(sigmaValues),trainErr,main="Training error depending on sigma",col="red",type="l",
xlab="Log Sigma",ylab="Error")
lines(log(sigmaValues),verifError,col="blue")
legend("right",0.002, 0.006, legend=c("Training error", "Verification error"),
col=c("red", "blue"), lty=1)
#Test en variant sigma
trainErr=c()
verifError=c()
A=0.01
B=100
M=20
sigmaValues=exp(seq(log(A),log(B),length=M))
for (i in 1:length(sigmaValues)){
REZsvmi = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=sigmaValues[i]),type="C-svc",cross=0,C=50)
Ypredi=predict(REZsvmi)
trainErr[i]=1-sum(Ypredi==Y)/length(Y)
newPredi=predict(REZsvmi,newdata=X2)
verifError[i]=1-sum(newPredi==Y2)/length(Y2)
}
plot(log(sigmaValues),trainErr,main="Training error depending on sigma",col="red",type="l",
xlab="Log(sigma)",ylab="Error")
lines(log(sigmaValues),verifError,col="blue")
legend("right",0.002, 0.006, legend=c("Training error", "Verification error"),
col=c("red", "blue"), lty=1)
###########
#Cross validation
cross(REZsvm)
REZcross = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=2),type="C-svc",cross=12,C=50)
cross(REZcross)
trainErr=c()
verifError=c()
A=0.01
B=100
M=20
sigmaValues=exp(seq(log(A),log(B),length=M))
for (i in 1:length(sigmaValues)){
REZsvmi = ksvm(X,Y,kernel="rbfdot", kpar=list(sigma=sigmaValues[i]),
type="C-svc",cross=0,C=50)
Ypredi=predict(REZsvmi)
trainErr[i]=1-sum(Ypredi==Y)/length(Y)
newPredi=predict(REZsvmi,newdata=X2)
verifError[i]=1-sum(newPredi==Y2)/length(Y2)
}
plot(log(sigmaValues),trainErr,main="Training error depending on sigma",
col="red",type="l",
xlab="Log(sigma)",ylab="Error")
lines(log(sigmaValues),verifError,col="blue")
legend("right",0.002, 0.006, legend=c("Verification error", "Training error"),
col=c("blue","red"), lty=1)
plot(log(sigmaValues),trainErr,main="Training error depending on sigma",
col="red",type="l",
xlab="Log(sigma)",ylab="Error")
lines(log(sigmaValues),verifError,col="blue")
legend("right",0.001, 0.002, legend=c("Verification error", "Training error"),
col=c("blue","red"), lty=1)
plot(log(sigmaValues),trainErr,main="Training error depending on sigma",
col="red",type="l",
xlab="Log(sigma)",ylab="Error")
lines(log(sigmaValues),verifError,col="blue")
legend("right",0.01, 0.02, legend=c("Verification error", "Training error"),
col=c("blue","red"), lty=1)
plot(log(sigmaValues),trainErr,main="Training error depending on sigma",
col="red",type="l",
xlab="Log(sigma)",ylab="Error")
lines(log(sigmaValues),verifError,col="blue")
legend("right",legend=c("Verification error", "Training error"),
col=c("blue","red"), lty=1)
legend("top",legend=c("Verification error", "Training error"),
col=c("blue","red"), lty=1)
plot(log(sigmaValues),trainErr,main="Training error depending on sigma",
col="red",type="l",
xlab="Log(sigma)",ylab="Error")
lines(log(sigmaValues),verifError,col="blue")
legend("top",legend=c("Verification error", "Training error"),
col=c("blue","red"), lty=1)
